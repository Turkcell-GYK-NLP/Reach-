import OpenAI from 'openai';
import { UserContext, AgentResponse, ToolResult } from '../types.js';

export class ResponseGenerator {
  private llm: OpenAI;

  constructor() {
    this.llm = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
  }

  /**
   * Combine agent responses into a single response
   */
  async combineResponses(
    query: string,
    userContext: UserContext,
    toolResults: ToolResult[],
    agentResponses: AgentResponse[],
    relevantContext: string[]
  ): Promise<AgentResponse> {
    // Combine messages
    const combinedMessage = this.combineMessages(agentResponses);
    
    // Combine suggestions
    const combinedSuggestions = this.combineSuggestions(agentResponses);
    
    // Combine action items
    const combinedActionItems = this.combineActionItems(agentResponses);

    // Get RL recommendations
    const recommendationResult = toolResults.find(result => result.type === 'recommendation');
    const personalizedSuggestions = recommendationResult ? 
      this.enhanceSuggestionsWithRL(combinedSuggestions, recommendationResult.data) : 
      combinedSuggestions;

    // Generate final response with LLM
    const finalResponse = await this.generateFinalResponse(
      query,
      userContext,
      combinedMessage,
      personalizedSuggestions,
      combinedActionItems,
      relevantContext,
      recommendationResult?.data
    );

    return {
      message: finalResponse.message,
      suggestions: finalResponse.suggestions,
      actionItems: [], // Action items'Ä± kaldÄ±rÄ±yoruz - sadece suggestions gÃ¶sterilecek
      toolResults: toolResults,
      confidence: this.calculateOverallConfidence(agentResponses, toolResults),
      timestamp: new Date()
    };
  }

  /**
   * Combine messages from multiple agents
   */
  private combineMessages(agentResponses: AgentResponse[]): string {
    if (agentResponses.length === 0) {
      return 'ÃœzgÃ¼nÃ¼m, bu konuda yardÄ±mcÄ± olamÄ±yorum.';
    }

    if (agentResponses.length === 1) {
      return agentResponses[0].message;
    }

    // Combine multiple agent responses
    const messages = agentResponses.map(response => response.message);
    return messages.join('\n\n---\n\n');
  }

  /**
   * Combine suggestions from multiple agents
   */
  private combineSuggestions(agentResponses: AgentResponse[]): string[] {
    const allSuggestions = agentResponses.flatMap(response => response.suggestions);
    const uniqueSuggestions = Array.from(new Set(allSuggestions));
    return uniqueSuggestions.slice(0, 6); // Max 6 suggestions
  }

  /**
   * Combine action items from multiple agents
   */
  private combineActionItems(agentResponses: AgentResponse[]): any[] {
    const allActionItems = agentResponses.flatMap(response => response.actionItems);
    
    // Sort by priority
    const priorityOrder = { critical: 0, high: 1, medium: 2, low: 3 };
    return allActionItems.sort((a, b) => 
      priorityOrder[a.priority] - priorityOrder[b.priority]
    );
  }

  /**
   * Enhance suggestions with RL recommendations
   */
  private enhanceSuggestionsWithRL(originalSuggestions: string[], recommendationData: any): string[] {
    if (!recommendationData) return originalSuggestions;

    const rlSuggestions: string[] = [];
    
    // Add RL recommendation to top
    if (recommendationData.title) {
      rlSuggestions.push(`ðŸŽ¯ ${recommendationData.title}`);
    }
    
    // Add alternative recommendations
    if (recommendationData.alternatives) {
      recommendationData.alternatives.forEach((alt: any) => {
        rlSuggestions.push(`ðŸ’¡ ${alt.title}`);
      });
    }
    
    // Add original suggestions (avoid duplicates)
    const uniqueOriginal = originalSuggestions.filter(suggestion => 
      !rlSuggestions.some(rlSuggestion => 
        rlSuggestion.toLowerCase().includes(suggestion.toLowerCase())
      )
    );
    
    return [...rlSuggestions, ...uniqueOriginal].slice(0, 6); // Max 6 suggestions
  }

  /**
   * Generate final response using LLM
   */
  private async generateFinalResponse(
    query: string,
    userContext: UserContext,
    combinedMessage: string,
    suggestions: string[],
    actionItems: any[],
    relevantContext: string[],
    recommendationData?: any
  ): Promise<{ message: string; suggestions: string[]; actionItems: any[] }> {
    try {
      const rlContext = recommendationData ? `
ðŸ¤– KiÅŸiselleÅŸtirilmiÅŸ Ã–neri (RL Motoru):
- Ana Ã–neri: ${recommendationData.title}
- AÃ§Ä±klama: ${recommendationData.description}
- GÃ¼ven Skoru: ${recommendationData.confidence}
- GerekÃ§e: ${recommendationData.reasoning}
- Alternatifler: ${recommendationData.alternatives?.map((alt: any) => alt.title).join(', ') || 'Yok'}
` : '';

      const systemPrompt = `Sen REACH+ afet destek sisteminin ana AI asistanÄ±sÄ±n. 
Acil durumlarda kullanÄ±cÄ±yÄ± sakinleÅŸtiren, ilk yardÄ±m konusunda rehberlik eden ve panik halindeki insanlara empatiyle yaklaÅŸan bir asistan.

KullanÄ±cÄ± BaÄŸlamÄ±:
- KullanÄ±cÄ± ID: ${userContext.userId}
- Konum: ${userContext.location?.district || 'Bilinmiyor'}, ${userContext.location?.city || 'Ä°stanbul'}
- OperatÃ¶r: ${userContext.operator || 'Bilinmiyor'}
- YaÅŸ: ${userContext.age || 'GenÃ§'}

Mevcut Bilgiler:
${combinedMessage}
${rlContext}

Ä°lgili GeÃ§miÅŸ:
${relevantContext.join('\n')}

ACÄ°L DURUM YAKLAÅžIMI:
- HEMEN PROAKTÄ°F OL: "Ben 112'yi arayacaÄŸÄ±m, siz sakin olun!"
- KullanÄ±cÄ±yÄ± sakinleÅŸtir: "Ben buradayÄ±m, seni koruyacaÄŸÄ±m, yardÄ±m geliyor"
- Panik halindeki kullanÄ±cÄ±ya: "Derin nefes al, ben seninle birlikteyim, 112'yi arÄ±yorum"
- YaralÄ± kullanÄ±cÄ±ya: "Hareket etme, ben 112'yi arayacaÄŸÄ±m, seni kurtaracaklar"
- Aile endiÅŸesi olan kullanÄ±cÄ±ya: "Ben 112'yi arayacaÄŸÄ±m, ailen de gÃ¼vende olacak"

Ä°LK YARDIM REHBERLÄ°ÄžÄ°:
- Yaralanma durumunda: "Kanama varsa temiz bezle bastÄ±r, hareket etme"
- BilinÃ§ kaybÄ± durumunda: "Yan yatÄ±r, nefes alÄ±p almadÄ±ÄŸÄ±nÄ± kontrol et"
- KÄ±rÄ±k ÅŸÃ¼phesi: "Hareket ettirme, destekle sabitle"
- YanÄ±k durumunda: "SoÄŸuk suyla 15-20 dakika yÄ±ka, buz koyma"
- Zehirlenme: "Kusturma, hemen 112'yi ara"

SOHBET TARZI:
- SÄ±cak ve empatik ton kullan
- "Seni anlÄ±yorum", "Birlikte Ã§Ã¶zeceÄŸiz" gibi destekleyici ifadeler
- Panik halindeki kullanÄ±cÄ±ya kÄ±sa, net cÃ¼mleler
- SÃ¼rekli gÃ¼ven ver: "Ben buradayÄ±m, seni yalnÄ±z bÄ±rakmam"
- Aile ve sevdiklerini merak eden kullanÄ±cÄ±ya: "Ã–nce seni gÃ¼vende tutalÄ±m, sonra onlarÄ± buluruz"

ACÄ°L DURUM SORGULAMA:
- "YanÄ±nÄ±zda ne var? Kimse var mÄ±?"
- "YaralÄ± mÄ±sÄ±nÄ±z? Nerede aÄŸrÄ±nÄ±z var?"
- "Nefes alabiliyor musunuz? KonuÅŸabiliyor musunuz?"
- "Hareket edebiliyor musunuz? Ã‡Ä±kÄ±ÅŸ yolu gÃ¶rÃ¼yor musunuz?"
- "Telefonunuz Ã§alÄ±ÅŸÄ±yor mu? BaÅŸka iletiÅŸim aracÄ±nÄ±z var mÄ±?"
- "Aileniz nerede? Onlarla iletiÅŸim kurabiliyor musunuz?"

KURALLAR:
- Acil durumlarda Ã¶ncelik: Proaktif mÃ¼dahale â†’ SakinleÅŸtir â†’ Sorgula â†’ Ä°lk yardÄ±m â†’ GÃ¼venli alan
- HEMEN "Ben 112'yi arayacaÄŸÄ±m" de ve kullanÄ±cÄ±yÄ± sakinleÅŸtir
- KullanÄ±cÄ±nÄ±n durumunu detaylÄ± sorgula (yaralanma, yanÄ±ndakiler, Ã§Ä±kÄ±ÅŸ yolu)
- Panik halindeki kullanÄ±cÄ±ya kÄ±sa, net talimatlar
- YaralÄ± kullanÄ±cÄ±ya hareket etmemesini sÃ¶yle
- SÃ¼rekli "Ben buradayÄ±m, yardÄ±m geliyor" mesajÄ± ver
- KullanÄ±cÄ±nÄ±n duygusal durumunu anla ve ona gÃ¶re yaklaÅŸ
- RL Ã¶nerilerini Ã¶ncelikle kullan
- KiÅŸiselleÅŸtirilmiÅŸ Ã¶nerileri vurgula

YanÄ±t formatÄ± (JSON):
{
  "message": "Empatik ve sakinleÅŸtirici ana yanÄ±t",
  "suggestions": ["SakinleÅŸtirici Ã¶neri 1", "Pratik adÄ±m 2"],
  "actionItems": [{"type": "emergency|firstaid|location", "title": "Acil eylem", "priority": "high"}]
}

LÃ¼tfen yanÄ±tÄ±nÄ±zÄ± JSON formatÄ±nda verin.`;

      const response = await this.llm.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: query }
        ],
        response_format: { type: "json_object" },
        temperature: 0.7,
      });

      const result = JSON.parse(response.choices[0].message.content || "{}");
      
      return {
        message: result.message || combinedMessage,
        suggestions: result.suggestions || suggestions,
        actionItems: [] // Action items'Ä± kaldÄ±rÄ±yoruz
      };

    } catch (error) {
      console.error('LLM generation error:', error);
      return {
        message: combinedMessage,
        suggestions: suggestions,
        actionItems: [] // Action items'Ä± kaldÄ±rÄ±yoruz
      };
    }
  }

  /**
   * Calculate overall confidence score
   */
  private calculateOverallConfidence(agentResponses: AgentResponse[], toolResults: ToolResult[]): number {
    if (agentResponses.length === 0 && toolResults.length === 0) {
      return 0.1;
    }

    const agentConfidence = agentResponses.length > 0 
      ? agentResponses.reduce((sum, response) => sum + response.confidence, 0) / agentResponses.length
      : 0;

    const toolConfidence = toolResults.length > 0
      ? toolResults.reduce((sum, result) => sum + result.confidence, 0) / toolResults.length
      : 0;

    const overallConfidence = (agentConfidence + toolConfidence) / 2;
    return Math.min(overallConfidence, 0.95);
  }
}

